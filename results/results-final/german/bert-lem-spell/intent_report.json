{
  "negate": {
    "precision": 0.7,
    "recall": 0.6363636363636364,
    "f1-score": 0.6666666666666666,
    "support": 11,
    "confused_with": {
      "provide": 3,
      "uninspiring": 1
    }
  },
  "accept": {
    "precision": 0.85,
    "recall": 0.8947368421052632,
    "f1-score": 0.8717948717948718,
    "support": 19,
    "confused_with": {
      "provide": 1,
      "negate": 1
    }
  },
  "uninspiring": {
    "precision": 0.5,
    "recall": 0.125,
    "f1-score": 0.2,
    "support": 16,
    "confused_with": {
      "provide": 14
    }
  },
  "provide": {
    "precision": 0.9539347408829175,
    "recall": 0.9900398406374502,
    "f1-score": 0.9716520039100685,
    "support": 502,
    "confused_with": {
      "negate": 2,
      "uninspiring": 1
    }
  },
  "accept_provide": {
    "precision": 0.9473684210526315,
    "recall": 0.6923076923076923,
    "f1-score": 0.7999999999999999,
    "support": 26,
    "confused_with": {
      "provide": 6,
      "accept": 2
    }
  },
  "accuracy": 0.9425087108013938,
  "macro avg": {
    "precision": 0.7902606323871098,
    "recall": 0.6676896022828084,
    "f1-score": 0.7020227084743214,
    "support": 574
  },
  "weighted avg": {
    "precision": 0.9326773847919738,
    "recall": 0.9425087108013938,
    "f1-score": 0.9332173203140945,
    "support": 574
  },
  "micro avg": {
    "precision": 0.9425087108013938,
    "recall": 0.9425087108013938,
    "f1-score": 0.9425087108013938,
    "support": 574
  }
}